<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>3D Digital Holographic Microscopy Water Quality Detection System</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="3D Digital Holographic Microscopy Water Quality Detection System">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="3D Digital Holographic Microscopy Water Quality Detection System">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Taven Chen">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="3D Digital Holographic Microscopy Water Quality Detection System" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">3D Digital Holographic Microscopy Water Quality Detection System</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Project-Introduction" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/11/Project-Introduction/" class="article-date">
  <time class="dt-published" datetime="2024-03-12T01:41:29.000Z" itemprop="datePublished">2024-03-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/11/Project-Introduction/">Project Introduction</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="About-this-project"><a href="#About-this-project" class="headerlink" title="About this project"></a>About this project</h1><p>This project introduces a new way to check water health by looking closely at tiny water creatures called plankton. With more pollution due to factories and cities, it’s getting harder to find clean water. Traditional methods to study water are slow. This project uses advanced technology to quickly and accurately study plankton, which helps us understand the quality of water. This method is faster, cheaper, and can spot very tiny details in plankton, making it a great tool for keeping an eye on water health.</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>Water covers most of the Earth but is not always easy to use because of pollution. This project focuses on studying small water creatures, plankton, to learn about water quality. Normally, checking water involves a lot of steps and waiting. But with new technologies like digital holographic microscopy, we can get faster and clearer pictures of plankton, helping us understand water quality better and quicker.</p>
<h1 id="2-Basic-Principles"><a href="#2-Basic-Principles" class="headerlink" title="2. Basic Principles"></a>2. Basic Principles</h1><h2 id="2-1-Lens-Free-On-Chip-Holography"><a href="#2-1-Lens-Free-On-Chip-Holography" class="headerlink" title="2.1 Lens-Free On-Chip Holography"></a>2.1 Lens-Free On-Chip Holography</h2><p>This simple method captures detailed images of plankton using light patterns. It doesn’t need complicated setups like traditional microscopes but still gives us very clear pictures. This helps us see the tiny details of plankton easily.</p>
<h2 id="2-2-Multi-Wavelength-Based-Phase-Recovery"><a href="#2-2-Multi-Wavelength-Based-Phase-Recovery" class="headerlink" title="2.2 Multi-Wavelength-Based Phase Recovery"></a>2.2 Multi-Wavelength-Based Phase Recovery</h2><p>By taking pictures at different light colors, this method lets us see plankton in even more detail. It uses special algorithms to make images clearer, allowing us to identify small plankton features important for water quality.</p>
<h2 id="2-3-Detection-of-Water-Quality-Through-Plankton"><a href="#2-3-Detection-of-Water-Quality-Through-Plankton" class="headerlink" title="2.3 Detection of Water Quality Through Plankton"></a>2.3 Detection of Water Quality Through Plankton</h2><p>Plankton changes tell us a lot about water health. This system uses advanced imaging to quickly spot these changes, making it easier to know if the water is clean or polluted.</p>
<h1 id="3-System-Design-and-Construction"><a href="#3-System-Design-and-Construction" class="headerlink" title="3. System Design and Construction"></a>3. System Design and Construction</h1><h2 id="3-1-Light-Path-System-Design"><a href="#3-1-Light-Path-System-Design" class="headerlink" title="3.1 Light Path System Design"></a>3.1 Light Path System Design</h2><p>The system uses special LED lights and filters to shine different light colors on plankton and captures these images with a camera sensor. This helps get a detailed look at plankton under various light conditions.</p>
<h2 id="3-2-Hardware-and-Circuit-Design"><a href="#3-2-Hardware-and-Circuit-Design" class="headerlink" title="3.2 Hardware and Circuit Design"></a>3.2 Hardware and Circuit Design</h2><p>The setup includes several parts controlled by a computer unit, making it easy to switch between different lighting conditions. This simplicity makes it possible to capture high-quality images of plankton for analysis.</p>
<h2 id="3-3-3D-Printing-and-Prototype-Building"><a href="#3-3-3D-Printing-and-Prototype-Building" class="headerlink" title="3.3 3D Printing and Prototype Building"></a>3.3 3D Printing and Prototype Building</h2><p>Using 3D printing, the system’s parts are made precisely and affordably. This approach makes the tool more accessible for monitoring water quality everywhere.</p>
<h1 id="4-Experimentation-and-Results"><a href="#4-Experimentation-and-Results" class="headerlink" title="4. Experimentation and Results"></a>4. Experimentation and Results</h1><p>The project tested the system with plankton samples and water from different places. Advanced image techniques were used to separate and count plankton in the images, showing the system’s accuracy in spotting water quality changes through detailed plankton analysis.</p>
<h1 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h1><p>The 3D Digital Holographic Microscopy Water Quality Detection System is a big step forward in monitoring water health. It’s quick, accurate, and affordable, making it easier to check water quality and protect our water resources. Future improvements could include using artificial intelligence to make the system even better at identifying and counting plankton.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/11/Project-Introduction/" data-id="cltjnzwjo0008uw7k2qdsbjwo" data-title="Project Introduction" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Abstract" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/10/Abstract/" class="article-date">
  <time class="dt-published" datetime="2024-03-11T02:05:47.000Z" itemprop="datePublished">2024-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/10/Abstract/">Abstract</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Water is essential for life but getting clean water is a challenge in many places due to pollution and how water is spread out across the Earth. This study looks at how important it is to check the quality of water, especially with more factories and cities growing. We focus on plankton, tiny water organisms that can tell us a lot about water’s health. When water gets polluted, the type and amount of plankton change, which is a warning sign of poor water quality. Traditional ways of studying plankton involve collecting water samples and analyzing them in labs, which takes a lot of time and can delay getting important information. To make this process faster and more accurate, we use new technologies like digital holographic microscopy (DHM) and lensless digital holographic microscopy (LDHM). These methods allow us to see plankton in great detail and quickly understand water quality.<br>We explain how we create and analyze images of plankton without using traditional lenses, using light and computers to capture and study these images in detail. This includes using different light wavelengths and advanced computing methods like the Gerchberg-Saxton (G-S) iteration for better image analysis, and techniques like level-set based cell image segmentation for counting and studying plankton cells accurately. Our experiments with these technologies showed that we could see tiny details in plankton, as small as 2.46 micrometers, which is almost as good as the best our equipment can do. This proves that our approach is effective for quickly checking water quality by looking at plankton.<br>By introducing these new technologies, we provide a faster and cheaper way to monitor water quality, which could help in understanding and protecting aquatic environments better. This research offers a new solution for quickly finding out about water quality through detailed study of plankton, showing a way forward for environmental monitoring.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/10/Abstract/" data-id="cltjnzwjg0001uw7k5sx67ztz" data-title="Abstract" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Introduction" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/09/Introduction/" class="article-date">
  <time class="dt-published" datetime="2024-03-10T03:05:55.000Z" itemprop="datePublished">2024-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/09/Introduction/">Introduction</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Water, covering two-thirds of the earth’s surface and permanently inundating nearly 4% of the global land mass, is a ubiquitous element. It undergoes a continuous cycle within the hydrosphere, evaporating from the earth’s surface, condensing in the atmosphere, and returning as liquid water. Despite its abundance, water scarcity is a common issue, particularly in regions with uneven distribution. While some places are well-watered, others face shortages, exacerbated by the increasing global population. Although the earth will not run out of water, variations in water quality persist. The majority of the earth’s water is too saline for human use, and pollution from human activities has further degraded the quality of fresh water, diminishing its utility. Even though evaporation serves as a natural water purification process, salts and pollutants left behind continue to contaminate the returning rainwater. Life in all its forms relies on water, making it a vital resource with complexities and challenges that must be addressed [1].<br>However, with the continuous advancement of industrialization and urbanization, limited water resources is also facing an increasingly serious risk of pollution. For example, on February 3, 2023, a train derailment in Ohio released toxic chemicals into the environment, causing significant water contamination for local residents. Therefore, the detection of water quality has become particularly important. The interconnectedness between the living water environment’s quality and underwater plankton is significant. Stable physiological characteristics, species, and numbers are exhibited by indigenous plankton in various waters. Swift responses to changes in the water body are observed in these organisms. When the water quality experiences pollution to different degrees, variations in plankton species occur due to differing bacterial densities in the water. Optimal water quality is distinguished by moderate pH values, high oxygen content, and low bacterial and microorganism content. In such conditions, higher oval algae, diatoms with columns, and corresponding zooplankton can thrive. Conversely, poor water quality accommodates organisms like sandshell worms, cyclopia, and algae-tolerant strong plankton. Severe water pollution results in high bacterial density, posing a challenge to the survival of most plankton. Only species with stronger pollution tolerance, such as nudibranchs, cyanobacteria, and caecilian earthworms, can endure. Therefore, examining underwater plankton species and quantity allows one to gather information about water quality and its trends, either directly or indirectly.<br>Observation forms the basis for many existing techniques in detecting underwater plankton. Initially, underwater plankton observation relies on a sampling approach. This involved using a sample collector or trawl at a specified water sampling site, and then transporting the sample to the laboratory. Subsequently, the sample underwent a certain degree of treatment, was fixed, and was preserved into observable slide samples. Finally, a laboratory microscope was employed for observation and identification. While sampling observation yields relatively abundant underwater plankton morphology data and reduces identification errors, it comes with notable drawbacks. The process of sampling, transporting to the laboratory, and studying the experimental results introduces significant delays, hindering the timely acquisition of large-scale experimental data for monitoring water quality pollution conditions. Therefore, the traditional sampling-based observation method falls short of meeting the current demands of underwater plankton research and development. To address this, the study of obtaining effective underwater plankton data on a large scale, both temporally and spatially, through relatively simple operations has become a crucial research focus. As multidisciplinary research gains momentum, researchers are increasingly exploring detection methods and tools from other disciplines. Techniques and tools from diverse fields, including biology, acoustics, optics, and electronics, have garnered attention and been integrated into underwater plankton detection research. One such noteworthy approach is the optical detection-based digital holographic imaging method, which stands out for its accuracy, comprehensive experimental data, and effective visualization of results, attracting the interest of experts and scholars with its broad research outcomes and application scope.</p>
<p><img src="/2024/03/09/Introduction/1.png" alt="Figure 1 Schematic diagram of sewage environment monitoring based on plankton"></p>
<p>Digital holographic microscopy (DHM) [2] is a widely adopted technique that enables the recording and reconstruction (via the digital holographic principle [3]) of an optical field modulated by various factors such as scattering, refraction, absorption, and reflection from a biomedical [4] or technical micro-object. Hologram demodulation techniques, including Fourier Transform [5], spatial carrier phase shifting [6], or Hilbert Transform [7], along with more precise multi-frame techniques like temporal phase shifting, can provide complex data at the registration plane. The reconstructed complex data contains information about amplitude (absorptive features) and phase (refractive features), which is crucial for label-free quantitative imaging. Over the past two decades, quantitative phase imaging has emerged as a leading framework for label-free live bio-specimen examination [8]. Post-reconstruction, numerical propagation of the optical field to the focus plane is achievable, for instance, using the angular spectrum (AS) method [9], especially when the hologram was captured outside the focus plane. The determination of the focus plane often involves automatic methods like autofocusing approaches [10], now also integrated into deep learning frameworks [11]. Quantitative phase microscopes following DHM principles, as well as traditional bright-field microscopes, are typically bulky with multiple optical elements. In contrast, lensless digital holographic microscopy (LDHM) [12], based on Gabor in-line holography [13], consists of a light source, a CCD camera, and a sample placed between them, preferably near the CCD matrix [14]. This configuration ensures a large field of view (FOV) primarily dependent on the size of the CCD matrix. Resolution in LDHM is mainly limited by the pixel size, requiring it to be small enough to capture dense Gabor holographic fringes without optical magnification [15]. The total number of pixels sampling the hologram is crucial for information bandwidth and resolution.<br>The recent advancement of lensless imaging owes much to the mass production of affordable digital image sensors with small pixel sizes and high pixel counts [16, 17], alongside improvements in computing power and reconstruction algorithms for processing captured diffraction patterns. Compared to conventional lens-based microscopy, lensless approaches offer key advantages, including a large space–bandwidth product, cost-effectiveness, portability, and depth-resolved three-dimensional imaging. These advantages make lensless imaging particularly suitable for analysis applications requiring extensive statistics, such as cytometry for “needle-in-a-haystack” diagnostic tasks like the Papanicolaou smear test for cervical cancer [18] and blood smear inspection for malaria diagnosis [19]. Lensless imaging is well-suited for studies demanding statistically significant estimates based on limited samples, as seen in the examination of thousands of sperm trajectories to identify rare types of motion [20] and the performance of a complete blood count [21]. Applications with varying number densities, such as air and water quality tests, benefit from lensless imaging’s large space–bandwidth product and depth of field. Lensless imaging is also an excellent choice for point-of-care and global health applications, where compact, portable, cost-effective, and widely distributed devices and approaches are essential. Unlike traditional microscopy, lensless imaging doesn’t require expensive precision microscope objective lenses and light sources. In many instances, individual light-emitting diodes suffice for illumination, and the most expensive component is the image sensor, which can be as low as a few tens of dollars due to mass-produced complementary metal-oxide-semiconductor image sensors for mobile phones [16, 17]. </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/09/Introduction/" data-id="cltjnzwjm0006uw7kgd9pdwie" data-title="Introduction" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Basic-Principles" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/08/Basic-Principles/" class="article-date">
  <time class="dt-published" datetime="2024-03-09T03:06:44.000Z" itemprop="datePublished">2024-03-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/08/Basic-Principles/">Basic Principles</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="2-1-Basic-principles-of-lens-free-on-chip-holography"><a href="#2-1-Basic-principles-of-lens-free-on-chip-holography" class="headerlink" title="2.1 Basic principles of lens-free on-chip holography"></a>2.1 Basic principles of lens-free on-chip holography</h2><p>Lens-free on-chip holography, an in-line digital holographic imaging technique, is introduced with a rearranged sequence of principles for basic recording and numerical reconstruction. The formation of the hologram H(x, y) occurs when a light source with sufficient spatial and temporal coherence illuminates the sample. This hologram is a result of the interference between the scattered light O(x, y) on the sample and the unscattered background light R(x, y). The expression for the hologram is given as:</p>
<script type="math/tex; mode=display">
H\left( {x,{\rm{ }}y} \right) = R\left( {x,{\rm{ }}y} \right) + O\left( {x,{\rm{ }}y} \right) = r\left( {x,{\rm{ }}y} \right) + o\left( {x,{\rm{ }}y} \right)exp\left[ { - j\varphi \left( {x,{\rm{ }}y} \right)} \right]{\rm{ }}</script><p>where r(x, y) and o(x, y) represent the amplitude information of the reference and object lights, and φ(x, y) is the phase information of the object light wave. The light intensity and phase information of the object light wave are obtained using the angular spectrum algorithm, expressed as:</p>
<script type="math/tex; mode=display">
\begin{aligned}
U(x,y,z) &= F^{ - 1}\{ F[H(x,y)] \times G(f_x,f_y,z)\}\\\\
G(f_x,f_y,z) &= exp[j \frac{2\pi z}{\lambda}\sqrt{1-(\lambda f_x)^2-(\lambda f_y)^2}]\to f_x^2+f_y^2  < \frac{1}{\lambda^2}\\\\
G(f_x,f_y,z) &= 0 \to f_x^2+f_y^2 \geq \frac{1}{\lambda^2}\\\\
I(x,y,z) &= |U(x,y,z)|^2\\\\
\phi(x,y,z) &= \arctan \{\frac{Im[U(x,y,z)]}{Re[U(x,y,z)]}\}
\end{aligned}</script><p>where $F$ and $ F^{-1} $ denote the Fourier transform and the inverse Fourier transform, respectively. G(fx, fy, z) is the optical transfer function in the frequency domain, λ is the wavelength of the light source, and $z$ is the distance from the sample to the sensor plane. In lens-free on-chip microscopy, the small distance ($z$ « $z_2$) between the sample and the sensor is crucial to expanding the field of view and improving resolution, typically ranging from 400 to 1,000 μm. Without a microscope objective, it is necessary to propagate the hologram back to the focal plane. The distance between the sample and the sensor is determined by the autofocusing algorithm in actual operation, resulting in a maximum field of view similar to the image sensor’s working area and a maximum image resolution approximating the sensor’s resolution.<br>However, the resolution of lens-free on-chip holography is limited by the pixel size of the sensor. To overcome this limitation, reconstruction based on multiple wavelengths is proposed as an effective super-resolution method, capable of removing twin-image simultaneously.</p>
<h2 id="2-2-Multi-wavelength-based-phase-recovery-algorithm"><a href="#2-2-Multi-wavelength-based-phase-recovery-algorithm" class="headerlink" title="2.2 Multi-wavelength-based phase recovery algorithm"></a>2.2 Multi-wavelength-based phase recovery algorithm</h2><p>In contrast to multi-height phase retrieval methods, the multi-wavelength approach hinges on capturing images of the same object illuminated by different wavelengths. While the reconstruction distance for a hologram acquired at one wavelength remains fixed, holograms obtained at other wavelengths can be reconstructed as if they were at a proportionately larger or smaller depth (Figure 2).</p>
<p><img src="/2024/03/08/Basic-Principles/1.png" alt="Figure 2  Schematic diagram of multi-wavelength lighting"><br><img src="/2024/03/08/Basic-Principles/2.png" alt="Figure 3  Multi-wavelength phase recovery algorithm flow chart"></p>
<p>As shown in Figure 3, the process of phase recovering separate to 6 main steps:</p>
<ol>
<li>Image Acquisition: Multiple holograms of the object are captured at different wavelengths of illumination, typically the primary colors of light—red (R), green (G), and blue (B).</li>
<li>Image Registration: The images acquired are aligned or registered to ensure they correspond to the same spatial locations.</li>
<li>Estimate Focusing Distance ($z$): The reconstruction distances for the holograms are estimated. While the distance for a given wavelength is fixed, other wavelengths can be virtually reconstructed at different depths, simulating a change in focus.</li>
<li>Initial Phase Calculation: An initial estimation of the object’s phase profile at one wavelength is made.</li>
<li>G-S Iterative Phase Recovery: This iterative process involves the Gerchberg-Saxton algorithm, which is used to recover phase information from intensity images. It alternates between the amplitude captured at one wavelength and the phase estimated at another, propagating the wavefront through virtual planes at different relative depths.</li>
<li>Guided Filtering: After the phase recovery, the result might be subjected to guided filtering to refine the outcome.<br>To find the reconstruction distance $z$ for each wavelength, the original distance $z_1$ is determined using wavelength $\lambda_1$, the rest $z_i$ corresponding $\lambda_i$ is directly proportional to $z_1$, which could be derived by multiplying the ratio of $\lambda$. So $z_{i}=z_{1} * \lambda_{i} / \lambda_{1}$.<h2 id="2-3-Principles-of-water-quality-detection-by-plankton"><a href="#2-3-Principles-of-water-quality-detection-by-plankton" class="headerlink" title="2.3 Principles of water quality detection by plankton"></a>2.3 Principles of water quality detection by plankton</h2>Phytoplankton serves as a critical indicator for assessing water quality, as its abundance and species composition are closely linked to the condition of a water body. Variations in phytoplankton populations, either through decline or excessive growth, signal a degradation in water health. Specifically, a surge in phytoplankton, particularly cyanobacteria, and an extended growth period are key indicators of eutrophication in lakes and reservoirs. Pollution directly impacts the species makeup of phytoplankton; while natural water bodies experience seasonal and environmental shifts in algal species composition, these changes are predictable. However, in polluted waters, the alterations in phytoplankton communities due to contaminants are irregular. Golden algae, which are particularly sensitive to environmental shifts, preferring cooler temperatures, low organic content, and high water clarity, demonstrate the most noticeable changes in polluted environments.</li>
</ol>
<p><img src="/2024/03/08/Basic-Principles/3.png" alt="Figure 4   Physical picture of plankton laboratory processing a: water filtering, b: filter paper cutting, c: filter paper redissolution"></p>
<p>In this experiment, in order to estimate the number of plankton in a large volume of water, which could be used to estimate the density of plankton in the whole water body, the water sample should first be concentrated for more efficient estimation. There are several steps in the concentration process.</p>
<ol>
<li>Collect water sample from the top of the water body with volume V(L)</li>
<li>Pass the water sample through Bottle Top Filtration Unit with 45 PES filter membrane (Figure 4a)</li>
<li>Carefully take off the membrane from the bottle</li>
<li>Take 1/6 of the membrane and cut into small pieces (Figure 4b)</li>
<li>Add 2 ml of DI water to a microcentrifuge tube</li>
<li>Put the pieces of the membrane into the tube</li>
<li>Put the tube on the vortex mixer for 1 minute (Figure 4c)</li>
<li>Extract 50 of the concentrated water sample and put it on the slide, then put the coverside on </li>
</ol>
<p>The overall water sample plankton density C (cells/L) after counting the number of plankton in the slide n can be calculated with.<br>Based on a previous experiment by the Ministry of Ecology and Environment of the People’s Republic of China [22], the following chart is used as a reference.<br><img src="/2024/03/08/Basic-Principles/4.png" alt="Table 1"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/08/Basic-Principles/" data-id="cltjnzwji0002uw7k6ad87j26" data-title="Basic Principles" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Plankton-detection-system-design-and-construction" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/07/Plankton-detection-system-design-and-construction/" class="article-date">
  <time class="dt-published" datetime="2024-03-08T03:07:04.000Z" itemprop="datePublished">2024-03-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/07/Plankton-detection-system-design-and-construction/">Plankton detection system design and construction</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="3-1-Overall-light-path-system-design"><a href="#3-1-Overall-light-path-system-design" class="headerlink" title="3.1 Overall light path system design"></a>3.1 Overall light path system design</h2><p>The diagram below illustrates the light path of the digital microscope, starting with an LED that provides a stable source of light. This light illuminates the specimen mounted on a slide, and the interaction between the light and the sample is captured by the CMOS. </p>
<p><img src="/2024/03/07/Plankton-detection-system-design-and-construction/1.png" alt="Figure 5   Schematic diagram of system optical path structure"></p>
<p>In order to have multi-wavelength light, there are several ways to complete this system. One is to let the LED become multi-wavelength so that it can emit different light on a different wavelength. Another is to add a multiple-filter control system, including a plate holding filter of different wavelengths and a servo. By turning the plate so that light passes through different filters, the different wavelengths of light can be achieved.</p>
<h2 id="3-2-Hardware-and-circuit-design"><a href="#3-2-Hardware-and-circuit-design" class="headerlink" title="3.2 Hardware and circuit design"></a>3.2 Hardware and circuit design</h2><p><img src="/2024/03/07/Plankton-detection-system-design-and-construction/2.png" alt="Figure 6   Schematic diagram of system hardware path structure"></p>
<p>The whole system contains a total of six components without the Micro Control Unit (MCU), mainly including the outer shell, slide holder, CMOS, servo with filter, and LED. The adjustable holder (2) is an instrument that can change the height of the plate precisely. To switch between different filters, a servo is used to rotate the plate to choose the filter. The LED light shell is designed to hold one white LED with an aluminum base. To connect the system with the MCU, the positive and negative wires of the servo and the positive wire of the LED are directly connected to the 5V and GND ports in the MCU. The signal wire of the servo is connected to the analog output port of the MCU, and the negative wire of the LED is connected to the digital output port of the MCU. By programming the MCU to control the related output in different ports, the LED switch and the position of the servo can be controlled. The output wire of the CMOS can be directly connected to the computer to record the picture captured, or if the MCU is Raspberry Pi or similar hardware that has USB-A and wireless communication equipment, the CMOS could also directly connect to the MCU and wirelessly read data on a computer for later analysis.</p>
<h2 id="3-3-3D-printing-and-prototype-building"><a href="#3-3-3D-printing-and-prototype-building" class="headerlink" title="3.3 3D printing and prototype building"></a>3.3 3D printing and prototype building</h2><p>For the outer shell, slide holder, and filter plate, the 3D printing material is photosensitive resin using the SLA process. An SG90 servo is used in this system because of its small size. A 5050 LED is used since it can separately control all three RGB values, and the distance between three small LEDs is in an acceptable range. A narrowband filter is used since a limited wavelength is required for the phase retrieving process to be accurate. The half-band width of the three filters is 20nm, and the wavelength for the three filters is 650nm, 532nm, and 450nm. The CMOS type is Basler dart daA2500-14um (No-Mount), with resolution (H x V) 2592 px × 1944 px, pixel Size (H x V) 2.2 μm × 2.2 μm, frame rate 14 fps, and mono color.<br>In order to assemble the system, the slide holder should be inserted into the supporting component in the middle bottom hole and fixed with glue. The CMOS and its supporting components should be fixed with a screw and nut. The wire should be appropriately carried out by drilling holes in the supporting component. After making sure the output port of the CMOS is exposed and gluing the front board of the supporting component on, assemble the filter plate with all three filters, and then attach the filter plate to the servo. Then, screw the servo and its supporting component to the outer shell, and make sure all wires are correctly connected as stated in the “Hardware and circuit design” section. Finally, assemble the outer shell with the supporting component, and do the first test of the system.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/07/Plankton-detection-system-design-and-construction/" data-id="cltjnzwjn0007uw7kg70hh3jc" data-title="Plankton detection system design and construction" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Experiment" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/06/Experiment/" class="article-date">
  <time class="dt-published" datetime="2024-03-07T03:07:18.000Z" itemprop="datePublished">2024-03-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/06/Experiment/">Experiment</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="4-1Plankton-slide-sample-testing"><a href="#4-1Plankton-slide-sample-testing" class="headerlink" title="4.1Plankton slide sample testing"></a>4.1Plankton slide sample testing</h2><p>In order to test the performance of the system, the sample slide of paramecium is used. After taking the background image (which follows the same process but without the slide on), there are several steps to follow:</p>
<ol>
<li>Fix the slide on the slide holder, and connect the camera to the receiver device.</li>
<li>Adjust the height of the slide holder to minimize the distance between the slide and the CMOS.</li>
<li>Open one of the RGB LEDs or turn the filter plate to one of the RGB filters.</li>
<li>Record the picture in the receiver (computer or MCU).</li>
<li>Repeat steps 3 and 4 to take pictures under all the lights.</li>
</ol>
<p>After taking the photo, three background images and three object images are processed as in Figure 4. The image before and after processing is shown in Figure 7.<br>Figure 10a provides the original image taken under green light of 525μm. As shown in Figure 10b, the clarity of the image greatly improved. Figure 7c shows the processed image of one specific paramecium. The 3D shape of one specific paramecium can be derived as shown in Figure 7d. </p>
<p><img src="/2024/03/06/Experiment/1.png" alt="Figure 7   Observation results of paramecium slide sample a: hologram b: light intensity diagram after processing c: light intensity of a single paramecium d: 3d image of a single paramecium"></p>
<h2 id="4-2Water-quality-sample-collection"><a href="#4-2Water-quality-sample-collection" class="headerlink" title="4.2Water quality sample collection"></a>4.2Water quality sample collection</h2><p>After making the concentrated water sample slide using the process illustrated in section 2.3, the sample can be recorded using the process illustrated in 4.1. The number of cells in the processed image can be calculated using level-set based cell image segmentation.<br>Level-set based cell image segmentation is an advanced image processing method for recognizing and segmenting cells from complex backgrounds. This technique is very important in biomedical imaging analysis, especially in cases where individual cells need to be accurately identified and quantified. The following is the basic process of level set based cell segmentation technique:</p>
<ol>
<li>Image Acquisition and Preprocessing: after processing to obtain images of the observed microorganisms, the images need to be pre-processed. This includes steps such as denoising, contrast adjustment, grayscaling etc.</li>
<li>Level Set Function: The level set method relies on a mathematical representation called the level set function, which is used to define the foreground (e.g., cells) and background in the image. The level set function is evolved through a mathematical formulation (usually a partial differential equation). This process causes the contours of the level set to gradually move towards the cell boundaries.</li>
<li>Segmenting the Cell: When the level set function is stable, i.e., the contour no longer changes significantly, it is considered to be close to or at the actual boundary of the cell. At this point, this contour can be used to segment out the cells in the image.</li>
<li>Post-processing: The segmented result may require some post-processing, such as removing regions that are too small (which may be noise), or merging regions that are very close together (which may be different parts of the same cell).</li>
</ol>
<p><img src="/2024/03/06/Experiment/2.png" alt="Figure 8   Cell identification technology"></p>
<p>The number of cells  calculated by the above method is only the number of cells inside the view of the CMOS. In order to estimate the complete number of cells on the slide , the ratio of the CMOS area  and slide area  is used for estimation with the formula ${n_t} = {n_c}*{S_s}/{S_c}$</p>
<p><img src="/2024/03/06/Experiment/3.png" alt="Figure 9   Water sample observation results a: hologram b: light intensity diagram after processing c: 3D image of a part of sample d: light intensity of a part of sample"></p>
<p>In Figure 9, the water sample from a pond in the Princeton area is processed using the above procedure. Figure 9a shows the original image of the concentrated water sample, and Figure 9b is the image after phase retrieval. Figure 9d shows the phase retrieved image of a small part of the image, and Figure 9c shows the 3d shape of the image.</p>
<h2 id="4-3-Overall-analysis"><a href="#4-3-Overall-analysis" class="headerlink" title="4.3 Overall analysis"></a>4.3 Overall analysis</h2><p><img src="/2024/03/06/Experiment/4.png" alt="Figure 10   Resolution board sample observations a: hologram b: light intensity diagram after processing c: 3D image"></p>
<p>In order to get a more systematic evaluation of the system, the USAF1951 resolution board is used. As shown in Figure 10, Figure 10a is the original image under green light of 525μm, and Figure 10b is the processed image. The system can capture at most group 7 element 5 clearly, which is 2.46μm. In this test case, the CMOS we tested has a pixel size of 2.2μm by 2.2μm, so the system is approaching the theory limit resolution of the hardware.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/06/Experiment/" data-id="cltjnzwjl0005uw7kd20gb7xa" data-title="Experiment" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Conclusion" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/05/Conclusion/" class="article-date">
  <time class="dt-published" datetime="2024-03-06T03:07:34.000Z" itemprop="datePublished">2024-03-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/05/Conclusion/">Conclusion</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Our study into digital holographic microscopy (DHM) and lensless digital holographic microscopy (LDHM) as tools for assessing water quality through plankton analysis marks a significant step towards innovative environmental monitoring methods. Plankton analysis stands out as a key indicator of water health, revealing that rapid and accurate detection of water quality changes is achievable. This approach significantly outperforms traditional methods, which are slower and may not keep pace with the swift changes in water bodies caused by pollution. The benefits of utilizing DHM and LDHM are manifold. These technologies enable quick observation and analysis of plankton, dramatically reducing the time needed to evaluate water quality. Through capturing high-detail plankton images and applying sophisticated image analysis algorithms like the G-S iteration and level-set based cell image segmentation, we manage to precisely measure and identify plankton species and quantities. Testing with the USAF1951 resolution board confirmed our system’s capability to distinguish features as small as 2.46μm, proving its high resolution and accuracy. Moreover, these optical techniques streamline the necessary equipment for plankton observation, making the process both more accessible and cost-effective. This opens up water quality monitoring to a broader audience, allowing more communities and researchers to perform their own assessments and make well-informed decisions on water management and conservation.<br>Looking ahead, there’s potential to build upon our findings. Future research might delve into incorporating artificial intelligence and machine learning to automate plankton identification and counting, which could further expedite and refine analysis accuracy. Expanding the plankton image database to include various conditions could enhance system sensitivity to different pollution types. Additionally, improving the portability and field-readiness of the equipment could extend its usability across varied environmental settings.<br>In closing, our investigation presents a solid proof of concept for applying advanced optical methods in water quality monitoring through plankton analysis. Advancing this groundwork, future endeavors can augment the efficiency, reach, and impact of water quality monitoring efforts, contributing significantly to the worldwide initiative to safeguard our essential water resources.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/05/Conclusion/" data-id="cltjnzwjj0003uw7kh3jj0eu7" data-title="Conclusion" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-References" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/04/References/" class="article-date">
  <time class="dt-published" datetime="2024-03-05T03:07:46.000Z" itemprop="datePublished">2024-03-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/04/References/">References</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <ol>
<li>Boyd, C. (2012). Water quality. Aquaculture: farming aquatic animals and plants. Wiley-Blackwell, Oxford, 52-83.</li>
<li>M.K. Kim, Digital Holographic Microscopy (Springer, 2011).</li>
<li>U. Schnars and W. Jueptner, Digital Holography (Springer, 2005).</li>
<li>B. Kemper and G. von Bally, “Digital holographic microscopy for live cell applications and technical inspection,” Appl. Opt. 47(4), A52–A61 (2008). </li>
<li>M. Takeda, H. Ina, and S. Kobayashi, “Fourier-transform method of fringe-pattern analysis for computer-based topography and interferometry,” J. Opt. Soc. Am. 72(1), 156–160 (1982). </li>
<li>M. Pirga and M. Kujawinska, “Two directional spatial-carrier phase-shifting method for analysis of crossed and closed fringe patterns,” Opt. Eng. 34(8), 2459 (1995). </li>
<li>T. Ikeda, G. Popescu, R. Dasari, and M. Feld, “Hilbert phase microscopy for investigating fast dynamics in transparent systems,” Opt. Lett. 30(10), 1165–1167 (2005). </li>
<li>Y. Park, C. Depeursinge, and G. Popescu, “Quantitative phase imaging in biomedicine,” Nat. Photonics 12(10), 578–589 (2018). </li>
<li>T. Kozacki and K. Falaggis, “Angular spectrum-based wave-propagation method with compact space bandwidth for large propagation distances,” Opt. Lett. 40(14), 3420–3423 (2015). </li>
<li>Y. Zhang, H. Wang, Y. Wu, M. Tamamitsu, and A. Ozcan, “Edge sparsity criterion for robust holographic autofocusing,” Opt. Lett. 42(19), 3824–3827 (2017). </li>
<li>Y. Wu, Y. Rivenson, Y. Zhang, Z. Wei, H. Günaydin, X. Lin, and A. Ozcan, “Extended depth-of-field in holographic imaging using deep-learning-based autofocusing and phase recovery,” Optica 5(6), 704–710 (2018). </li>
<li>A. Ozcan and E. McLeod, “Lensless Imaging and Sensing,” Annu. Rev. Biomed. Eng. 18(1), 77–102 (2016). </li>
<li>E. McLeod and A. Ozcan, “Unconventional methods of imaging: computational microscopy and compact implementations,” Rep. Prog. Phys. 79(7), 076001 (2016). </li>
<li>D. Gabor, “A New Microscopic Principle,” Nature 161(4098), 777–778 (1948). </li>
<li>T. Agbana, H. Gong, A. Amoah, V. Bezzubik, M. Verhaegen, and G. Vdovin, “Aliasing, coherence, and resolution in a lensless holographic microscope,” Opt. Lett. 42(12), 2271–2274 (2017).</li>
<li>Vashist SK, Mudanyali O, Schneider EM, Zengerle R, Ozcan A. 2013. Cellphone-based devices for bioanalytical sciences. Anal. Bioanal. Chem. 406:3263–77</li>
<li>Ozcan A. 2014. Mobile phones democratize and cultivate next-generation imaging, diagnostics and measurement tools. Lab Chip 14:3187–94</li>
<li>Greenbaum A, Ozcan A. 2012. Maskless imaging of dense samples using pixel super-resolution based multi-height lensfree on-chip microscopy. Opt. Expr. 20:3129–43</li>
<li>Bishara W, Sikora U, Mudanyali O, Su T-W, Yaglidere O, et al. 2011. Handheld, lensless microscope identifies malaria parasites. SPIE Newsroom, Aug. 5. <a target="_blank" rel="noopener" href="http://spie.org/x51571.xml">http://spie.org/x51571.xml</a></li>
<li>Su T-W, Choi I, Feng J, Huang K, McLeod E, Ozcan A. 2013. Sperm trajectories form chiral ribbons. Sci. Rep. 3:1664</li>
<li>Seo S, Isikman SO, Sencan I, Mudanyali O, Su T-W, et al. 2010. High-throughput lens-free blood analysis on a chip. Anal. Chem. 82:4621–27</li>
<li>Ministry of Ecology and Environment of the People’s Republic of China. (2021). Water quality—Determination of Phytoplankton—Membrane filtration method (Report No. HJ 1216-2021). Ministry of Ecology and Environment of the People’s Republic of China <a target="_blank" rel="noopener" href="https://big5.mee.gov.cn/gate/big5/www.mee.gov.cn/xxgk2018/xxgk/xxgk06/202009/W020200930591312856871.pdf">https://big5.mee.gov.cn/gate/big5/www.mee.gov.cn/xxgk2018/xxgk/xxgk06/202009/W020200930591312856871.pdf</a></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/04/References/" data-id="cltjnzwjo0009uw7k8laxa5o6" data-title="References" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-3D-File-and-Example-Code" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/03/3D-File-and-Example-Code/" class="article-date">
  <time class="dt-published" datetime="2024-03-04T04:46:34.000Z" itemprop="datePublished">2024-03-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/03/3D-File-and-Example-Code/">3D File and Example Code</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Onshape-Link"><a href="#Onshape-Link" class="headerlink" title="Onshape Link"></a>Onshape <a target="_blank" rel="noopener" href="https://cad.onshape.com/documents/80765a34c88936d525e218de/w/6d75fd85b5a20e104695a9fb/e/c8cdb905a5ae44a445df2235?renderMode=0&amp;uiState=65ebe940f796063448ef12cc">Link</a></h2><h2 id="STL-and-STEP-Link"><a href="#STL-and-STEP-Link" class="headerlink" title="STL and STEP Link"></a>STL and STEP <a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/117JgYtibwazW8vcyshTyD4lJbJIDRfy5?usp=sharing">Link</a></h2><h2 id="Past-Hologram-Example-Link"><a href="#Past-Hologram-Example-Link" class="headerlink" title="Past Hologram Example Link"></a>Past Hologram Example <a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/1C1ZPQBMflhSPHbYmJCQM6sJDG4yRPPTs?usp=sharing">Link</a></h2><h2 id="Example-code-of-single-wavelength-reconstruction-to-estimate-the-distance"><a href="#Example-code-of-single-wavelength-reconstruction-to-estimate-the-distance" class="headerlink" title="Example code of single wavelength reconstruction (to estimate the distance):"></a>Example code of single wavelength reconstruction (to estimate the distance):</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">close all;</span><br><span class="line">clear;</span><br><span class="line">set(<span class="number">0</span>,<span class="string">&#x27;defaultfigurecolor&#x27;</span>,<span class="string">&#x27;w&#x27;</span>);<span class="comment">%background color white</span></span><br><span class="line">I=imread(<span class="string">&#x27;G.tiff&#x27;</span>); <span class="comment">%Hologram</span></span><br><span class="line">I0=imread(<span class="string">&#x27;BG.tiff&#x27;</span>); <span class="comment">%Background</span></span><br><span class="line">I = double(I); </span><br><span class="line">I0 = double(I0); </span><br><span class="line">[N,M]=<span class="built_in">size</span>(I);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>);imshow(I,[]);title(<span class="string">&#x27;Original Hologram&#x27;</span>);       </span><br><span class="line">I1=I;</span><br><span class="line">Rect=<span class="built_in">round</span>(getrect);                                                    </span><br><span class="line">Xmin=<span class="built_in">max</span>(Rect(<span class="number">1</span>),<span class="number">1</span>);                                                   </span><br><span class="line">Ymin=<span class="built_in">max</span>(Rect(<span class="number">2</span>),<span class="number">1</span>);       </span><br><span class="line">Xmax=(Rect(<span class="number">1</span>)+Rect(<span class="number">3</span>));</span><br><span class="line">Ymax=(Rect(<span class="number">2</span>)+Rect(<span class="number">4</span>));</span><br><span class="line"><span class="built_in">hold</span> on;</span><br><span class="line"><span class="built_in">plot</span>([Xmin Xmax Xmax Xmin Xmin],[Ymin Ymin Ymax Ymax Ymin],<span class="string">&#x27;r&#x27;</span>);       </span><br><span class="line"><span class="built_in">hold</span> off;</span><br><span class="line">I1=I(Ymin:Ymax,Xmin:Xmax);   </span><br><span class="line">[N,M]=<span class="built_in">size</span>(I1);   </span><br><span class="line">I0=I0(Ymin:Ymax,Xmin:Xmax);   </span><br><span class="line">lamda=<span class="number">525</span>*<span class="number">10</span>^<span class="number">-9</span>;</span><br><span class="line"><span class="keyword">for</span> kk = <span class="number">0</span>:<span class="number">1</span></span><br><span class="line"> <span class="comment">%d=(0.6+0.4*kk/10)*10^-3;   </span></span><br><span class="line"> d=<span class="number">0.88</span>*<span class="number">10</span>^<span class="number">-3</span>;<span class="comment">%Estimated Distance</span></span><br><span class="line">k=<span class="number">1.5</span>*<span class="built_in">pi</span>/lamda;</span><br><span class="line">dx=<span class="number">2.2</span>*<span class="number">10</span>^<span class="number">-6</span>;                                  </span><br><span class="line">dy=<span class="number">2.2</span>*<span class="number">10</span>^<span class="number">-6</span>;</span><br><span class="line">dfx=<span class="number">1</span>/(M*dx);                                     </span><br><span class="line">dfy=<span class="number">1</span>/(N*dy);</span><br><span class="line">fx=<span class="built_in">ones</span>(N,<span class="number">1</span>)*(-M/<span class="number">2</span>:M/<span class="number">2</span><span class="number">-1</span>)*dfx;</span><br><span class="line">fy=(<span class="built_in">ones</span>(M,<span class="number">1</span>)*(-N/<span class="number">2</span>:N/<span class="number">2</span><span class="number">-1</span>)*dfy)&#x27;;</span><br><span class="line">    hol_fft111=fftshift(fft2(I1));     </span><br><span class="line">    hol_fft=fftshift(fft2(I1));                          </span><br><span class="line">    obj_fft=hol_fft.*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>*k*(-d)*<span class="built_in">sqrt</span>(<span class="number">1</span>-lamda^<span class="number">2</span>*(fx.^<span class="number">2</span>+fy.^<span class="number">2</span>))); </span><br><span class="line">    obj=ifft2(ifftshift( obj_fft));</span><br><span class="line">    amp_obj=<span class="built_in">abs</span>(obj);</span><br><span class="line">    obj_phase=<span class="built_in">angle</span>(obj);</span><br><span class="line"> <span class="built_in">figure</span>(kk+<span class="number">3</span>);imshow( amp_obj,[]);title(<span class="string">&#x27;Intensity&#x27;</span>);  </span><br><span class="line"> <span class="comment">%figure(3);imshow( amp_obj,[]);title(&#x27;Intensity&#x27;);  </span></span><br><span class="line"> <span class="comment">%figure(4);imshow( obj_phase,[]);title(&#x27;Phase&#x27;);             </span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">phase1=obj_phase;</span><br><span class="line">AAA=I1./I0;</span><br><span class="line">amp_hol=I1./I0;</span><br><span class="line"> hol_phase=<span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span> kk = <span class="number">1</span>:<span class="number">10</span>     </span><br><span class="line">    hol=amp_hol.*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>.*hol_phase);                  </span><br><span class="line">    hol_fft=fftshift(fft2(hol));                        </span><br><span class="line">    obj_fft=hol_fft.*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>*k*(-d)*<span class="built_in">sqrt</span>(<span class="number">1</span>-lamda^<span class="number">2</span>*(fx.^<span class="number">2</span>+fy.^<span class="number">2</span>))); </span><br><span class="line">    obj=ifft2(ifftshift( obj_fft));</span><br><span class="line">    amp_obj=<span class="built_in">abs</span>(obj);</span><br><span class="line">    obj_phase=<span class="built_in">angle</span>(obj);</span><br><span class="line">    <span class="comment">%obj_phase(amp_obj&gt;0.58)=-obj_phase(amp_obj&gt;0.58);     </span></span><br><span class="line">    amp_obj(amp_obj&gt;<span class="number">0.88</span>)=<span class="number">1</span>;</span><br><span class="line">    <span class="comment">%amp_obj=kkk;</span></span><br><span class="line">    obj_1=amp_obj.*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>.*obj_phase);</span><br><span class="line">    obj_1_fft=fftshift(fft2(obj_1)); </span><br><span class="line">    hol_fft=obj_1_fft.*<span class="built_in">exp</span>(<span class="number">1</span><span class="built_in">i</span>*k*(d)*<span class="built_in">sqrt</span>(<span class="number">1</span>-lamda^<span class="number">2</span>*(fx.^<span class="number">2</span>+fy.^<span class="number">2</span>))); </span><br><span class="line">    hol=ifft2(ifftshift(  hol_fft));</span><br><span class="line">    hol_phase=<span class="built_in">angle</span>(hol);</span><br><span class="line"> <span class="keyword">end</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">5</span>);imshow(<span class="built_in">abs</span>(obj),[]);title(<span class="string">&#x27;Intensity&#x27;</span>); </span><br><span class="line"><span class="built_in">figure</span>(<span class="number">6</span>);imshow(<span class="built_in">angle</span>(obj),[]);title(<span class="string">&#x27;Phase&#x27;</span>);  </span><br><span class="line">I=<span class="built_in">abs</span>(obj);</span><br><span class="line">P=<span class="built_in">angle</span>(obj);</span><br><span class="line">mesh(P);</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/03/3D-File-and-Example-Code/" data-id="cltjnzwjb0000uw7kgz8tgw0p" data-title="3D File and Example Code" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Contact" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/03/Contact/" class="article-date">
  <time class="dt-published" datetime="2024-03-03T05:03:06.000Z" itemprop="datePublished">2024-03-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/03/Contact/">Contact</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Email-Tavenchen-outlook-com"><a href="#Email-Tavenchen-outlook-com" class="headerlink" title="Email: Tavenchen@outlook.com"></a>Email: Tavenchen@outlook.com</h2><h2 id="Githun-https-github-com-chenwen051116"><a href="#Githun-https-github-com-chenwen051116" class="headerlink" title="Githun :https://github.com/chenwen051116"></a>Githun :<a target="_blank" rel="noopener" href="https://github.com/chenwen051116">https://github.com/chenwen051116</a></h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/03/Contact/" data-id="cltjnzwjk0004uw7k9dgq6lb6" data-title="Contact" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/11/Project-Introduction/">Project Introduction</a>
          </li>
        
          <li>
            <a href="/2024/03/10/Abstract/">Abstract</a>
          </li>
        
          <li>
            <a href="/2024/03/09/Introduction/">Introduction</a>
          </li>
        
          <li>
            <a href="/2024/03/08/Basic-Principles/">Basic Principles</a>
          </li>
        
          <li>
            <a href="/2024/03/07/Plankton-detection-system-design-and-construction/">Plankton detection system design and construction</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Taven Chen<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>